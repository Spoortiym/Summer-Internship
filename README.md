# Summer-Internship
Detecting and Mitigating Measurement Bias in AI Systems
Project Overview
This project focuses on detecting and mitigating measurement bias in AI systems to ensure fairness, accuracy, and ethical decision-making. Using the UCI Adult Dataset, the study explores statistical methods for bias detection and employs pre-processing, in-processing, and post-processing techniques to mitigate bias effectively.

Key Features
Implementation of fairness metrics such as Demographic Parity, Equalized Odds, and Calibration.
Application of bias mitigation techniques:
Pre-Processing: Data rebalancing, SMOTE, and reweighting.
In-Processing: Adversarial debiasing and fairness-aware training.
Post-Processing: Threshold adjustment and re-ranking.
Evaluation of model performance before and after mitigation using fairness and accuracy metrics.

Technologies Used
Programming Language: Python
Libraries:
Pandas and NumPy for data manipulation
Matplotlib and Seaborn for visualization
Scikit-learn for machine learning models and metrics
Imbalanced-learn for SMOTE
Dataset: UCI Adult Dataset
